# vLLM Server Configuration
OPENAI_BASE_URL=http://localhost:8000/v1
OPENAI_API_KEY=EMPTY

# Model Configuration
# MODEL_NAME is optional - will be auto-detected from server via /v1/models
# MODEL_NAME=Qwen/Qwen1.5-0.5B
MAX_CONTEXT_TOKENS=8192

# Agent Configuration
MAX_ACTIVE_CHARACTERS_PER_TURN=10
RNG_SEED=1337

# Storyteller Memory
STORYTELLER_MAX_HISTORY_TURNS=20

# Temperature Settings (optional overrides)
DIRECTOR_TEMPERATURE=0.2
STORYTELLER_TEMPERATURE=0.7
CHARACTER_DEFAULT_TEMPERATURE=0.7

# Token Limits (configured in core/config.py)
# DIRECTOR_MAX_TOKENS=10240 (routing decisions for multiple characters)
# STORYTELLER_MAX_TOKENS=15000 (outlines, world context, narratives)
# CHARACTER_MAX_TOKENS=1800 (individual character responses)

# Database
DATABASE_URL=sqlite:///./core.db

# API Server
API_HOST=127.0.0.1
API_PORT=8081
